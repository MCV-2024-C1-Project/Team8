{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "46dd3a8a071b0289",
   "metadata": {},
   "source": [
    "# C1 W1 Group 8"
   ]
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import seaborn as sns\n",
    "\n",
    "from src.data import GT_QSD1_W1_LIST\n",
    "from src.paths import BBDD_PATH, QSD1_W1_PATH\n",
    "from src.descriptors import GreyScaleHistogramDescriptor1D, HSVHistogramDescriptor1D, RGBHistogramDescriptor1D\n",
    "from src.similarities import MSE, L1Distance, ChiSquaredDistance, HistogramIntersection, HellingerKernel"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "6b66796f60ea572d",
   "metadata": {},
   "source": "## Task 1 - Create Museum and query image descriptors (BBDD & QSD1)"
  },
  {
   "cell_type": "markdown",
   "id": "811c0635209d74c9",
   "metadata": {},
   "source": [
    "The functions in this section are required to take a PIL.Image object as input and return a 1D descriptor in the form of a NumPy array. Inside the function, you have the freedom to implement any processing or transformation steps as long as the input and output types are respected. Specifically:\n",
    "\n",
    "    Input: A PIL.Image object, which can be manipulated or processed as needed.\n",
    "    Output: A 1D descriptor, represented as a NumPy array, which could be a histogram, feature vector, or any other type of descriptor derived from the input image."
   ]
  },
  {
   "cell_type": "code",
   "id": "65e2851e3382a177",
   "metadata": {},
   "source": [
    "# Replace with the function you want to use to generate the descriptors\n",
    "\n",
    "descriptors_classes = [\n",
    "    GreyScaleHistogramDescriptor1D(),\n",
    "    RGBHistogramDescriptor1D(),\n",
    "    HSVHistogramDescriptor1D()\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "eb921ea0163bd8d3",
   "metadata": {},
   "source": [
    "# Database image descriptors\n",
    "\n",
    "database_image_PIL_list = [Image.open(db_img_path) for db_img_path in BBDD_PATH.glob(\"*.jpg\")]  # Load once\n",
    "database_image_descriptors_list = [np.array([descriptor.compute(database_image_PIL) for database_image_PIL in database_image_PIL_list]) for descriptor in descriptors_classes]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "24d6a0a96dfa2ae5",
   "metadata": {},
   "source": [
    "# Query image descriptors\n",
    "\n",
    "query_image_PIL_list = [Image.open(query_img_path) for query_img_path in QSD1_W1_PATH.glob(\"*.jpg\")]  # Load once\n",
    "query_image_descriptors_list = [np.array([descriptor.compute(query_image_PIL) for query_image_PIL in query_image_PIL_list]) for descriptor in descriptors_classes]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "9536a0bb6b60c6b5",
   "metadata": {},
   "source": [
    "for idx, query_image_descriptors in enumerate(query_image_descriptors_list):\n",
    "    bins = np.arange(query_image_descriptors.shape[1])\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for i, hist in enumerate(query_image_descriptors):\n",
    "        plt.plot(bins, hist, label=f'Image {i}')\n",
    "    plt.title(f'Descriptor {descriptors_classes[idx].__class__.__name__}')\n",
    "    plt.xlabel('Bins')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend(fontsize=6)\n",
    "    plt.grid(True)\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "e8f0b16a042630cd",
   "metadata": {},
   "source": [
    "## Task 2 - Implement / compute similarity measures to compare images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bfbb767d7ed82e1",
   "metadata": {},
   "source": [
    "In this section, the functions should implement various distance measures between query descriptors and database descriptors. The input for both the query and database will be a 2D NumPy array, where each row represents the descriptor of one image. Specifically:\n",
    "\n",
    "    Query descriptors will have shape (N, K), where N is the number of query images, and K is the length of each descriptor.\n",
    "    Database descriptors will have shape (M, K), where M is the number of database images, and K is the length of each descriptor.\n",
    "\n",
    "The output should be a 2D array of shape (N, M), where each entry (i, j) represents the distance between query descriptor N_i and database descriptor M_j."
   ]
  },
  {
   "cell_type": "code",
   "id": "9527f4214cb37076",
   "metadata": {},
   "source": [
    "similarity_classes = [\n",
    "    MSE(),\n",
    "    L1Distance(),\n",
    "    ChiSquaredDistance(),\n",
    "    HistogramIntersection(),\n",
    "    HellingerKernel(),\n",
    "]"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "3aa68098da4a9193",
   "metadata": {},
   "source": [
    "query_descriptor_distances_to_bbdd_list = []\n",
    "for query_descriptors, database_descriptors in zip(query_image_descriptors_list, database_image_descriptors_list):\n",
    "    query_distances_to_bbdd = []\n",
    "    for similarity_function in similarity_classes:\n",
    "        query_distances_to_bbdd.append(similarity_function.compute(query_descriptors, database_descriptors))\n",
    "    query_descriptor_distances_to_bbdd_list.append(query_distances_to_bbdd)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Define the number of rows and columns based on descriptors and similarity classes\n",
    "n_rows = len(descriptors_classes)\n",
    "n_cols = len(similarity_classes)\n",
    "\n",
    "# Create a figure with subplots for each descriptor-similarity pair\n",
    "fig, axes = plt.subplots(n_rows, n_cols, figsize=(35, 10))  # Adjust figsize as needed for your plot\n",
    "\n",
    "# Iterate through each descriptor and similarity function\n",
    "for i, descriptor in enumerate(descriptors_classes):\n",
    "    for j, similarity in enumerate(similarity_classes):\n",
    "        query_distances_to_bbdd = query_descriptor_distances_to_bbdd_list[i][j]\n",
    "        \n",
    "        # Normalize the distances\n",
    "        normalized_query_distances = (query_distances_to_bbdd - query_distances_to_bbdd.min(axis=0)) / (query_distances_to_bbdd.max(axis=0) - query_distances_to_bbdd.min(axis=0))\n",
    "        \n",
    "        # Select the subplot axes for the current descriptor-similarity pair\n",
    "        ax = axes[i, j]\n",
    "        \n",
    "        # Use seaborn heatmap to display the distance matrix\n",
    "        sns.heatmap(normalized_query_distances, cmap=\"RdBu_r\", cbar=(j == n_cols - 1), ax=ax)\n",
    "        \n",
    "        # Add labels and title\n",
    "        ax.set_xlabel('Database Images')\n",
    "        ax.set_ylabel('Query Images')\n",
    "        ax.set_title(f'{descriptor.__class__.__name__} {similarity.__class__.__name__}')\n",
    "        \n",
    "# Adjust the layout to prevent overlapping labels\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the entire figure\n",
    "plt.show()"
   ],
   "id": "ff185e3ab5e3bda0",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "23dc7163138fbbef",
   "metadata": {},
   "source": [
    "## Task 3 - Implement retrieval system (retrieve top K results)"
   ]
  },
  {
   "cell_type": "code",
   "id": "3800600eef416463",
   "metadata": {},
   "source": [
    "def get_topk_distances(query_distances_to_bbdd: np.array, k: int = 1) -> tuple[list[list], list[list]]:\n",
    "    # Get the indices of the top k minimum values for each row\n",
    "    retrieved_bbdd_indices = np.argsort(query_distances_to_bbdd, axis=1)[:, :k]\n",
    "    \n",
    "    # Gather the top k scores using the indices\n",
    "    retrieved_bbdd_similarity = np.take_along_axis(query_distances_to_bbdd, retrieved_bbdd_indices, axis=1)\n",
    "    \n",
    "    return retrieved_bbdd_indices.tolist(), retrieved_bbdd_similarity.tolist()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "d484b207dca33ec8",
   "metadata": {},
   "source": [
    "# Select number of results to be retrieved\n",
    "k = 1"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "50e81df66a1d8028",
   "metadata": {},
   "source": [
    "retrieved_bbdd_indices_list = []\n",
    "retrieved_bbdd_similarity_list = []\n",
    "for query_descriptor_distances_to_bbdd in query_descriptor_distances_to_bbdd_list:\n",
    "    retrieved_bbdd_indices_tmp = []\n",
    "    retrieved_bbdd_similarity_tmp = []\n",
    "    for query_distances_to_bbdd in query_descriptor_distances_to_bbdd:\n",
    "        retrieved_bbdd_indices, retrieved_bbdd_similarity = get_topk_distances(query_distances_to_bbdd, k=k)\n",
    "        retrieved_bbdd_indices_tmp.append(retrieved_bbdd_indices)\n",
    "        retrieved_bbdd_similarity_tmp.append(retrieved_bbdd_similarity)\n",
    "    retrieved_bbdd_indices_list.append(retrieved_bbdd_indices_tmp)\n",
    "    retrieved_bbdd_similarity_list.append(retrieved_bbdd_similarity_tmp)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "for descriptor, retrieved_bbdd_indices, retrieved_bbdd_similarity in zip(descriptors_classes, retrieved_bbdd_indices_list, retrieved_bbdd_similarity_list):\n",
    "    for similarity, retrieved_similarity_bbdd_indices, retrieved_similarity_bbdd_similarity in zip(similarity_classes, retrieved_bbdd_indices, retrieved_bbdd_similarity):\n",
    "        print(descriptor.__class__.__name__, similarity.__class__.__name__, retrieved_similarity_bbdd_indices, retrieved_similarity_bbdd_similarity, \"\\n\")"
   ],
   "id": "c59c6ae3c593c4d5",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "52ca389d6a253917",
   "metadata": {},
   "source": [
    "# Metrics\n",
    "\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "assert False, \"Fix the following code\"",
   "id": "9197017707f6e9bc",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "a97d8508736f4dc6",
   "metadata": {},
   "source": [
    "# Visualization\n",
    "\n",
    "# Plot the images in a subplot\n",
    "n = len(GT_QSD1_W1_LIST)  # Number of rows (ground truth images)\n",
    "\n",
    "# Create a figure with n rows and k+1 columns (for the GT and N pred images)\n",
    "fig, axs = plt.subplots(n, k + 2, figsize=(3 * (k + 2), 3 * n))\n",
    "\n",
    "# Loop through each ground truth and predicted images\n",
    "for i in range(n):\n",
    "    # Load ground truth image\n",
    "    query_image_path = QSD1_W1_PATH / f\"{str(i).zfill(5)}.jpg\"\n",
    "    query_image_PIL = Image.open(query_image_path)\n",
    "\n",
    "    # Plot ground truth image in the first column\n",
    "    axs[i, 0].imshow(query_image_PIL)\n",
    "    axs[i, 0].set_title(f\"QUERY - {query_image_path.name}\")\n",
    "    axs[i, 0].axis('off')\n",
    "\n",
    "    # Load ground truth image\n",
    "    gt_idx = GT_QSD1_W1_LIST[i][0]  # only one index in GT\n",
    "    database_image_path = BBDD_PATH / f\"bbdd_{str(gt_idx).zfill(5)}.jpg\"\n",
    "    database_image_PIL = Image.open(database_image_path)\n",
    "\n",
    "    # Plot ground truth image in the first column\n",
    "    axs[i, 1].imshow(database_image_PIL)\n",
    "    axs[i, 1].set_title(f\"BBDD: {database_image_path.name}\")\n",
    "    axs[i, 1].axis('off')\n",
    "\n",
    "    # Loop through the retrieved images\n",
    "    for j in range(k):\n",
    "        retrieved_idx = indices[i][j]  # 'k' indices retrieved\n",
    "        retrieved_image_path = BBDD_PATH / f\"bbdd_{str(retrieved_idx).zfill(5)}.jpg\"\n",
    "        retrieved_image_PIL = Image.open(retrieved_image_path)\n",
    "        axs[i, j + 2].imshow(retrieved_image_PIL)\n",
    "        axs[i, j + 2].set_title(f\"PRED {j} - {retrieved_image_path.name}\")\n",
    "        axs[i, j + 2].axis('off')\n",
    "\n",
    "# Adjust layout\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "1cfcbe66daddcae7",
   "metadata": {},
   "source": [
    "## Task 4 - Create predictions for blind challenge (QST1)"
   ]
  },
  {
   "cell_type": "code",
   "id": "a58d40a2833c399f",
   "metadata": {},
   "source": [],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
