{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.descriptors import LBPDescriptor, DCTDescriptor, WaveletDescriptor, GaborDescriptor\n",
    "\n",
    "from src.data import GT_QSD1_W3_LIST\n",
    "from src.paths import (\n",
    "    BBDD_PATH, \n",
    "    QSD1_W3_PATH, \n",
    "    QSD1_NON_AUGMENTED_W3_PATH, \n",
    "    WEEK_3_PATH, \n",
    "    WEEK_3_RESULTS_PATH\n",
    ")\n",
    "from src.similarities import HistogramIntersection, CosineSimilarity\n",
    "from src.metrics import MeanAveragePrecisionAtK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_image_PIL_list = [Image.open(db_img_path) for db_img_path in sorted(BBDD_PATH.glob(\"*.jpg\"))]  # Load once\n",
    "query_d1_image_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD1_W3_PATH.glob(\"*.jpg\"))]  # Load once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_descriptors = [\n",
    "    #WaveletDescriptor(wavelet='haar', level=3),  #triga molt poc\n",
    "    #WaveletDescriptor(wavelet='db1',  level=4),  #triga molt poc\n",
    "    #LBPDescriptor(num_points=8, radius=1),   # triga mig\n",
    "    # LBPDescriptor(num_points=24, radius=3),  # triga molt\n",
    "    GaborDescriptor(),\n",
    "    DCTDescriptor(N=10),                     # triga poc\n",
    "    DCTDescriptor(N=21),                     # triga poc\n",
    "    # DCTDescriptor(N=36),                   # triga poc\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_levels = [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the execution faster we persist the partitions of the images for the next runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition_image(image: Image.Image, N: int):\n",
    "    w, h = image.size\n",
    "    part_width, part_height = w // N, h // N\n",
    "    return [image.crop((col * part_width, row * part_height,\n",
    "                        (col + 1) * part_width, (row + 1) * part_height))\n",
    "            for row in range(N) for col in range(N)]\n",
    "\n",
    "\n",
    "def process_partitioned_images(path, PIL_list, partition_levels, mode='auto'):\n",
    "    partitioned_images = {}\n",
    "    \n",
    "    for partition_level in partition_levels:\n",
    "        partition_level_dir = path.with_name(f\"{path.stem}_level_{partition_level}{path.suffix}\")\n",
    "\n",
    "        # Load existing partitions from disk if they exist and mode allows loading\n",
    "        if mode != 'compute' and partition_level_dir.exists():\n",
    "            partitioned_images[partition_level] = []\n",
    "\n",
    "            for img_idx in tqdm(range(len(PIL_list)), desc=f\"Loading images at level {partition_level}\"): \n",
    "                partitions = []\n",
    "                block_idx = 0\n",
    "                while True:\n",
    "                    img_path = partition_level_dir / f\"img_{img_idx}_block_{block_idx}.jpg\"\n",
    "                    if not img_path.exists():\n",
    "                        break  \n",
    "                    with Image.open(img_path) as img:  # Use context manager\n",
    "                        partitions.append(img.copy())\n",
    "                    block_idx += 1\n",
    "\n",
    "                partitioned_images[partition_level].append(partitions)\n",
    "\n",
    "            continue  # Skip computation for this level\n",
    "\n",
    "        # If partitions don't exist, or if mode is 'compute', calculate and store partitions\n",
    "        partition_level_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if partition_level == 1:\n",
    "            print(\"Partitioning at level 1\")\n",
    "            partitioned_images[partition_level] = [[img] for img in PIL_list]\n",
    "        else:\n",
    "            partitioned_images[partition_level] = [\n",
    "                partition_image(img, partition_level) \n",
    "                for img in tqdm(PIL_list, desc=f\"Partitioning at level {partition_level}\")\n",
    "            ]\n",
    "\n",
    "        # Save computed partitions to disk\n",
    "        for img_idx, partitions in tqdm(enumerate(partitioned_images[partition_level]), \n",
    "                                        total=len(partitioned_images[partition_level]), \n",
    "                                        desc=f\"Saving images at level {partition_level}\"):\n",
    "            for block_idx, block_img in enumerate(partitions):\n",
    "                block_img.save(partition_level_dir / f\"img_{img_idx}_block_{block_idx}.jpg\")\n",
    "\n",
    "    return partitioned_images\n",
    "\n",
    "\n",
    "partitioned_images_query = process_partitioned_images(WEEK_3_RESULTS_PATH/\"partitioned_query\",query_d1_image_PIL_list, partition_levels)\n",
    "partitioned_images_db = process_partitioned_images(WEEK_3_RESULTS_PATH/\"partitioned_db\",database_image_PIL_list, partition_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_partitioned_histograms(descriptors, partition_levels, partitioned_images):\n",
    "    partitioned_histograms = {}\n",
    "\n",
    "    for descriptor in descriptors:\n",
    "        print(\"Descriptor: \", descriptor.name)\n",
    "        partitioned_histograms[descriptor.name] = {}\n",
    "\n",
    "        for partition_level in partition_levels:\n",
    "            partitioned_histograms[descriptor.name][partition_level] = []\n",
    "\n",
    "            for partitions in tqdm(partitioned_images[partition_level], desc=f\"Processing partitions at level {partition_level}\"):\n",
    "                histograms_img = []\n",
    "                for partition_img in partitions:\n",
    "                    histogram_partition = descriptor.compute(np.array(partition_img))\n",
    "                    histograms_img.append(histogram_partition)\n",
    "\n",
    "                concatenated_histogram = np.concatenate(histograms_img, axis=0)\n",
    "                partitioned_histograms[descriptor.name][partition_level].append(concatenated_histogram)\n",
    "\n",
    "    return partitioned_histograms\n",
    "\n",
    "def save_load_histograms(path, compute_func, *args):\n",
    "    if path.exists():\n",
    "        return load_histograms(path)\n",
    "    else:\n",
    "        histograms = compute_func(*args)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(histograms, f)\n",
    "        return histograms\n",
    "\n",
    "def load_histograms(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "partitioned_histograms_query = save_load_histograms(WEEK_3_RESULTS_PATH/\"partitioned_histograms_query.pkl\", process_partitioned_histograms, texture_descriptors, partition_levels, partitioned_images_query)\n",
    "partitioned_histograms_db = save_load_histograms(WEEK_3_RESULTS_PATH/\"partitioned_histograms_db.pkl\", process_partitioned_histograms, texture_descriptors, partition_levels, partitioned_images_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_classes = [\n",
    "    HistogramIntersection(),\n",
    "    CosineSimilarity()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_descriptor_distances_to_db_list = {}\n",
    "\n",
    "for similarity in similarity_classes:\n",
    "    similarity_name = similarity.__class__.__name__\n",
    "    query_descriptor_distances_to_db_list[similarity_name] = {}\n",
    "\n",
    "    for descriptor in texture_descriptors: \n",
    "        descriptor_name = descriptor.name\n",
    "        print(f\"- {similarity_name} & {descriptor_name}\")\n",
    "\n",
    "        query_descriptor_distances_to_db_list[similarity_name][descriptor_name] = {}\n",
    "        \n",
    "        # Compute BB similarities for each partition level\n",
    "        for partition_level in partition_levels:\n",
    "            partitioned_db_desc = np.array(partitioned_histograms_db[descriptor_name][partition_level])\n",
    "            partitioned_query_desc = np.array(partitioned_histograms_query[descriptor_name][partition_level])\n",
    "            \n",
    "            bb_similarity = similarity.compute(partitioned_query_desc, partitioned_db_desc)\n",
    "            query_descriptor_distances_to_db_list[similarity_name][descriptor_name][partition_level] = bb_similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_distances(query_distances_to_bbdd: np.array, k: int = 1) -> tuple[list[list], list[list]]:\n",
    "    retrieved_bbdd_indices = np.argsort(query_distances_to_bbdd, axis=1)[:, :k]\n",
    "    \n",
    "    retrieved_bbdd_similarity = np.take_along_axis(query_distances_to_bbdd, retrieved_bbdd_indices, axis=1)\n",
    "    \n",
    "    return retrieved_bbdd_indices.tolist(), retrieved_bbdd_similarity.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define k (number of top results to retrieve)\n",
    "k = 5\n",
    "\n",
    "retrieved_db = {\n",
    "\n",
    "}\n",
    "\n",
    "for similarity_name, descriptors_dict in query_descriptor_distances_to_db_list.items():\n",
    "    retrieved_db[similarity_name] = {}\n",
    "    for descriptor_name, data_dict in descriptors_dict.items():\n",
    "        print(similarity_name, descriptor_name)\n",
    "        retrieved_db[similarity_name][descriptor_name] = {}\n",
    "\n",
    "        # BB Top-k retrieval for each partition level\n",
    "        bb_similarity = data_dict\n",
    "        for partition_level, distances in bb_similarity.items():\n",
    "            retrieved_db[similarity_name][descriptor_name][partition_level] = {}\n",
    "            topk_indices_bb, topk_similarities_bb = get_topk_distances(distances, k)\n",
    "            retrieved_db[similarity_name][descriptor_name][partition_level][\"indexes\"] = topk_indices_bb\n",
    "            retrieved_db[similarity_name][descriptor_name][partition_level][\"similarities\"] = topk_similarities_bb\n",
    "            print(f\"Top-{k} for {similarity_name} - {descriptor_name} (BB Level {partition_level}):\")\n",
    "            print(f\"Indices: {topk_indices_bb}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [MeanAveragePrecisionAtK()]\n",
    "K = [1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Descriptor</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Method</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K                   Metric                                  Descriptor  \\\n",
       "0   1  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "1   1  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "2   1  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "3   1  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "4   1  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "5   1  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "6   5  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "7   5  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "8   5  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "9   5  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "10  5  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "11  5  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "\n",
       "               Similarity         Method  Result  \n",
       "0   HistogramIntersection  BB at level 5    0.87  \n",
       "1   HistogramIntersection  BB at level 5    0.90  \n",
       "2   HistogramIntersection  BB at level 5    0.87  \n",
       "3        CosineSimilarity  BB at level 5    0.93  \n",
       "4        CosineSimilarity  BB at level 5    0.87  \n",
       "5        CosineSimilarity  BB at level 5    0.90  \n",
       "6   HistogramIntersection  BB at level 5    0.90  \n",
       "7   HistogramIntersection  BB at level 5    0.91  \n",
       "8   HistogramIntersection  BB at level 5    0.90  \n",
       "9        CosineSimilarity  BB at level 5    0.94  \n",
       "10       CosineSimilarity  BB at level 5    0.87  \n",
       "11       CosineSimilarity  BB at level 5    0.90  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "for i, k in enumerate(K):\n",
    "    for metric in metrics:\n",
    "        for similarity in similarity_classes:\n",
    "            similarity_name = similarity.__class__.__name__\n",
    "            for descriptor in texture_descriptors:\n",
    "                descriptor_name = descriptor.name\n",
    "\n",
    "\n",
    "                # BB\n",
    "                for partition_level in partition_levels:\n",
    "                    indexes_retrieved = retrieved_db[similarity_name][descriptor_name][partition_level][\"indexes\"]\n",
    "                    map_val = round(metric.compute(GT_QSD1_W3_LIST, indexes_retrieved, k), 2)\n",
    "                    results.append({\n",
    "                        \"K\": k,\n",
    "                        \"Metric\": metric.__class__.__name__,\n",
    "                        \"Descriptor\": descriptor_name,\n",
    "                        \"Similarity\": similarity_name,\n",
    "                        \"Method\": f\"BB at level {partition_level}\",\n",
    "                        \"Result\": map_val,\n",
    "                        \"Indices\": indexes_retrieved,\n",
    "                    })\n",
    "\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df_cleaned = results_df.drop(columns=[\"Indices\", \"Descriptor_id\", \"Similarity_id\"], errors='ignore')\n",
    "\n",
    "results_df_cleaned"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
