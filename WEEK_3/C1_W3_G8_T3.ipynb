{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "243ad852fc68d7d2",
   "metadata": {},
   "source": "# C1 W3 Group 8 - Task 3"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "This notebook begins with an initial *Research* section where various methods were explored to assess their behavior in solving the task at hand. During this exploratory phase, different algorithms and approaches were evaluated to identify the most effective solution.\n",
    "\n",
    "Following this research, the notebook culminates in a section titled *Final Implementation*. In this part, you'll find the finalized code, which has been simplified and cleaned for clarity and efficiency. This implementation reflects the insights gained from the earlier research, ensuring that it represents the best possible algorithm based on the findings."
   ],
   "id": "5737b87aa3c28bee"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Research",
   "id": "d07b16fe69f809de"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "from pathlib import Path\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "from src.paths import QSD2_W3_PATH, WEEK_3_RESULTS_PATH\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import cv2\n",
    "from skimage import filters"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Parameters",
   "id": "6ecfc6d87f42e2e6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "METHOD = \"gradient_magnitude\"\n",
    "KERNEL_SIZE = 5\n",
    "N_MARGIN_COLS = 10\n",
    "N_MARGIN_ROWS = 10\n",
    "APPLY_MEDIAN_FILTER = True"
   ],
   "id": "9cd58776b2e82fba",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Data loading",
   "id": "252f0c3825c7f479"
  },
  {
   "cell_type": "code",
   "id": "988536713d7476e7",
   "metadata": {},
   "source": [
    "query_d2_image_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD2_W3_PATH.glob(\"*.jpg\"))]  # Load once\n",
    "query_d2_mask_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD2_W3_PATH.glob(\"*.png\"))]  # Load once"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def filter_rgb_image(image: Image) -> Image:\n",
    "    # Split the image into its RGB channels\n",
    "    r, g, b = cv2.split(np.array(image))\n",
    "    \n",
    "    # Apply median filter to each channel\n",
    "    r_filtered = cv2.medianBlur(r, 3)\n",
    "    g_filtered = cv2.medianBlur(g, 3)\n",
    "    b_filtered = cv2.medianBlur(b, 3)\n",
    "    \n",
    "    # Merge the filtered channels back\n",
    "    return Image.fromarray(cv2.merge([r_filtered, g_filtered, b_filtered]))"
   ],
   "id": "b4d98af923b00dd8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "if APPLY_MEDIAN_FILTER:\n",
    "    query_d2_image_PIL_list = [filter_rgb_image(image) for image in query_d2_image_PIL_list]"
   ],
   "id": "489e1ebcb3e0257a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Functions",
   "id": "a20ebe80356dc7d9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_images(images, n_cols: int = 3, output_file: str | Path | None = None):\n",
    "    # Calculate number of rows needed\n",
    "    n_rows = (len(images) + n_cols - 1) // n_cols\n",
    "    \n",
    "    # Create subplots\n",
    "    fig, axes = plt.subplots(n_rows, n_cols, figsize=(10, 3 * n_rows))\n",
    "    \n",
    "    # Flatten axes array for easier iteration (in case there are multiple rows)\n",
    "    axes = axes.ravel()\n",
    "    \n",
    "    # Loop over the images and display them\n",
    "    for idx, image in enumerate(images):\n",
    "        axes[idx].imshow(image)\n",
    "        axes[idx].axis('off')  # Turn off axis labels\n",
    "    \n",
    "    # Turn off the remaining axes if there are any\n",
    "    for idx in range(len(images), n_rows * n_cols):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    if output_file is not None:\n",
    "        plt.savefig(str(output_file), bbox_inches='tight')\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()"
   ],
   "id": "8cf9dc1549ba2960",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def show_image_with_mean_values(image_array):\n",
    "    image_array = np.copy(image_array)\n",
    "    image_array = (image_array - image_array.min()) / (image_array.max() - image_array.min())\n",
    "    \n",
    "    mean_rows = image_array.mean(axis=1)\n",
    "    mean_cols = image_array.mean(axis=0)\n",
    "    \n",
    "    # Calculate thresholds using Otsu's method\n",
    "    threshold_rows = filters.threshold_otsu(mean_rows)\n",
    "    threshold_cols = filters.threshold_otsu(mean_cols)\n",
    "\n",
    "    # Create a figure with subplots\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    grid = plt.GridSpec(2, 2, width_ratios=[1, 1], height_ratios=[1, 1], hspace=0, wspace=0)\n",
    "    \n",
    "    # Main image\n",
    "    ax_image = fig.add_subplot(grid[1, 0])\n",
    "    ax_image.imshow(image_array, aspect='auto')\n",
    "\n",
    "    # Plot mean of columns (on the top)\n",
    "    ax_cols = fig.add_subplot(grid[0, 0], sharex=ax_image)\n",
    "    ax_cols.plot(np.arange(len(mean_cols)), (mean_cols > threshold_cols), color='black')\n",
    "    ax_cols.plot(np.arange(len(mean_cols)), mean_cols, color='red')\n",
    "    ax_cols.axhline(y=threshold_cols, color='green', linestyle='--', label=f'Threshold = {threshold_cols:.2f}')\n",
    "    ax_cols.set_xticks([])\n",
    "    ax_cols.set_yticks([0, 0.25, 0.5, 0.75, 1])  # Set ticks for normalized values\n",
    "    ax_cols.set_yticklabels([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax_cols.grid(True)  # Add grid\n",
    "\n",
    "    # Plot mean of rows (on the right)\n",
    "    ax_rows = fig.add_subplot(grid[1, 1], sharey=ax_image)\n",
    "    ax_rows.plot((mean_rows > threshold_rows), np.arange(len(mean_rows)), color='black')\n",
    "    ax_rows.plot(mean_rows, np.arange(len(mean_rows)), color='blue')    \n",
    "    ax_rows.axvline(x=threshold_rows, color='green', linestyle='--', label=f'Threshold = {threshold_rows:.2f}')\n",
    "    ax_rows.set_xticks([0, 0.25, 0.5, 0.75, 1])  # Set ticks for normalized values\n",
    "    ax_rows.set_xticklabels([0, 0.25, 0.5, 0.75, 1])\n",
    "    ax_rows.set_yticks([])\n",
    "    ax_rows.grid(True)  # Add grid\n",
    "    \n",
    "    plt.show()"
   ],
   "id": "1e2468323567ddf",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fill_mask(array, side: str):\n",
    "    # Make a copy\n",
    "    array = np.copy(array)\n",
    "    \n",
    "    # Calculate rows and columns with sufficient non-zero pixel percentage\n",
    "    mean_rows = (array > 0).mean(axis=1)\n",
    "    mean_cols = (array > 0).mean(axis=0)\n",
    "    \n",
    "    # Calculate thresholds using Otsu's method\n",
    "    threshold_rows = filters.threshold_otsu(mean_rows)\n",
    "    threshold_cols = filters.threshold_otsu(mean_cols)\n",
    "\n",
    "    # Get the indices of valid rows and columns\n",
    "    y_nonzero_indices = np.nonzero((mean_rows > threshold_rows))[0]\n",
    "    x_nonzero_indices = np.nonzero((mean_cols > threshold_cols))[0]\n",
    "\n",
    "    # Get the first and last valid positions\n",
    "    y_ini, y_end = y_nonzero_indices.min(), y_nonzero_indices.max()\n",
    "    x_ini, x_end = x_nonzero_indices.min(), x_nonzero_indices.max()\n",
    "    \n",
    "    # Special conditions when filling cropped paintings\n",
    "    # if painting touches right side (left crop)\n",
    "    if side == \"left\" and array[(mean_rows > threshold_rows), -1].any():\n",
    "        x_end = array.shape[1]\n",
    "    # elif painting touches left side (right crop)\n",
    "    elif side == \"right\" and array[(mean_rows > threshold_rows), 0].any():\n",
    "        x_ini = 0\n",
    "\n",
    "    # Fill the area between the first and last valid positions with the fill value\n",
    "    array[y_ini:y_end + 1, x_ini:x_end + 1] = 255\n",
    "    \n",
    "    # Set all values outside the indexed range to 0\n",
    "    array[:y_ini, :] = 0  # Above the valid range\n",
    "    array[y_end + 1:, :] = 0  # Below the valid range\n",
    "    array[:, :x_ini] = 0  # Left of the valid range\n",
    "    array[:, x_end + 1:] = 0  # Right of the valid range\n",
    "    \n",
    "    return array  # Return once filling is done"
   ],
   "id": "d53b7aaf66bc0dc5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def apply_otsu_to_image(image: np.ndarray) -> np.ndarray:\n",
    "    return (image > filters.threshold_otsu(image)).astype(np.uint8) * 255"
   ],
   "id": "51bfe6a74029135a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_gradient_magnitude(image: np.ndarray) -> np.ndarray:\n",
    "    # Define kernels for different edge orientations\n",
    "    kernely = np.array([\n",
    "        [1] * KERNEL_SIZE,\n",
    "        [1] * KERNEL_SIZE, \n",
    "        [0] * KERNEL_SIZE, \n",
    "        [-1] * KERNEL_SIZE,\n",
    "        [-1] * KERNEL_SIZE\n",
    "    ])   # Vertical\n",
    "    kernelx = np.copy(kernely).T  # Horizontal\n",
    "    \n",
    "    # Calculate gradients\n",
    "    gradient_x = cv2.filter2D(image, cv2.CV_64F, kernelx)\n",
    "    gradient_y = cv2.filter2D(image, cv2.CV_64F, kernely)\n",
    "    \n",
    "    # Calculate gradient magnitudes\n",
    "    gradient_magnitude = np.sqrt(gradient_x ** 2 + gradient_y ** 2)\n",
    "    \n",
    "    return gradient_magnitude"
   ],
   "id": "44ca768d697468a5",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def get_painting_mask(image: Image, method: str) -> (np.ndarray, np.ndarray):\n",
    "    if method == \"saturation\":\n",
    "        _, S, _ = image.convert(\"HSV\").split()\n",
    "        S = np.array(S)\n",
    "        left_S, right_S = S[:, :S.shape[1]//2], S[:, S.shape[1]//2:]\n",
    "        left_mask, right_mask = apply_otsu_to_image(left_S), apply_otsu_to_image(right_S)\n",
    "    elif method == \"gradient_magnitude\":\n",
    "        L = np.array(image.convert(\"L\"))\n",
    "        left_L, right_L = L[:, :L.shape[1]//2], L[:, L.shape[1]//2:]\n",
    "        left_L_gradient_magnitude, right_L_gradient_magnitude = get_gradient_magnitude(left_L), get_gradient_magnitude(right_L)\n",
    "        left_mask, right_mask = apply_otsu_to_image(left_L_gradient_magnitude), apply_otsu_to_image(right_L_gradient_magnitude)\n",
    "    else:\n",
    "        raise RuntimeError(f\"Method {method} not supported\")\n",
    "    return left_mask, right_mask"
   ],
   "id": "506f583673b4b90f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def correct_vertical_transition_in_concatenated_mask(mask: np.ndarray) -> np.ndarray:\n",
    "    corrected_mask = np.zeros(mask.shape, dtype=np.float32)\n",
    "    \n",
    "    nonzero_rows, nonzero_cols = np.nonzero(mask)\n",
    "    top_left_y = nonzero_rows[nonzero_cols == nonzero_cols.min()].min()\n",
    "    top_right_y = nonzero_rows[nonzero_cols == nonzero_cols.max()].min()\n",
    "    bottom_left_y = nonzero_rows[nonzero_cols == nonzero_cols.min()].max()\n",
    "    bottom_right_y = nonzero_rows[nonzero_cols == nonzero_cols.max()].max()\n",
    "    \n",
    "    n_cols_of_linspace = nonzero_cols.max() - nonzero_cols.min()\n",
    "    \n",
    "    top_y_linspace = np.linspace(top_left_y, top_right_y, num=n_cols_of_linspace, endpoint=True, dtype=int)\n",
    "    bottom_y_linspace = np.linspace(bottom_left_y, bottom_right_y, num=n_cols_of_linspace, endpoint=True, dtype=int)\n",
    "    x_linspace = np.linspace(nonzero_cols.min(), nonzero_cols.max(), num=n_cols_of_linspace, endpoint=True, dtype=int)\n",
    "    \n",
    "    for y in range(corrected_mask.shape[0]):\n",
    "        for idx in range(len(x_linspace)):\n",
    "            if top_y_linspace[idx] <= y <= bottom_y_linspace[idx]:\n",
    "                corrected_mask[y, x_linspace[idx]] = 255\n",
    "    \n",
    "    return corrected_mask"
   ],
   "id": "8592e30d1941c9e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def fill_painting_mask(mask: np.ndarray, side: str) -> (np.ndarray, np.ndarray, np.ndarray):\n",
    "    # Fill raw mask\n",
    "    filled_mask = fill_mask(mask, side)\n",
    "    \n",
    "    # Find connected components\n",
    "    num_labels, labels, stats, _ = cv2.connectedComponentsWithStats(mask)\n",
    "    \n",
    "    # `stats[:, cv2.CC_STAT_AREA]` gives the area of each component.\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]  # Ignore background\n",
    "    indices = np.arange(len(areas))\n",
    "    \n",
    "    if side == \"left\":\n",
    "        labels[:, :N_MARGIN_COLS] = 0\n",
    "    elif side == \"right\":\n",
    "        labels[:, -N_MARGIN_COLS:] = 0\n",
    "    labels[:N_MARGIN_ROWS] = 0\n",
    "    labels[-N_MARGIN_ROWS:] = 0\n",
    "    \n",
    "    indices += 1  # Add 1 to correct for the ignored background\n",
    "    \n",
    "    largest_components_mask = np.isin(labels, indices).astype(np.uint8) * 255\n",
    "    filled_largest_components_mask = fill_mask(largest_components_mask, side)\n",
    "    \n",
    "    return filled_mask, largest_components_mask, filled_largest_components_mask"
   ],
   "id": "bf2681865357294d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def compute_metrics(ground_truth, predicted):\n",
    "    # Ensure the inputs are numpy arrays\n",
    "    ground_truth = np.asarray(ground_truth).astype(bool)\n",
    "    predicted = np.asarray(predicted).astype(bool)\n",
    "    \n",
    "    # Calculate True Positives (TP), False Positives (FP), and False Negatives (FN)\n",
    "    TP = np.sum((predicted == 1) & (ground_truth == 1))  # True Positives\n",
    "    FP = np.sum((predicted == 1) & (ground_truth == 0))  # False Positives\n",
    "    FN = np.sum((predicted == 0) & (ground_truth == 1))  # False Negatives\n",
    "    \n",
    "    # Precision, Recall, F1-score, IoU\n",
    "    precision = TP / (TP + FP) if (TP + FP) > 0 else 0\n",
    "    recall = TP / (TP + FN) if (TP + FN) > 0 else 0\n",
    "    f1_score = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "    iou = TP / (TP + FP + FN) if (TP + FP + FN) > 0 else 0\n",
    "    \n",
    "    # Create a DataFrame with the metrics for a single mask comparison\n",
    "    metrics_df = pd.DataFrame({\n",
    "        'Precision': [precision],\n",
    "        'Recall': [recall],\n",
    "        'F1-score': [f1_score],\n",
    "        'IoU': [iou]\n",
    "    })\n",
    "    \n",
    "    return metrics_df\n",
    "\n",
    "def compute_average_metrics(ground_truth_list, predicted_list):\n",
    "    assert len(ground_truth_list) == len(predicted_list), \"Lists must have the same length\"\n",
    "    \n",
    "    metrics_list = []\n",
    "    \n",
    "    for gt_mask, pred_mask in zip(ground_truth_list, predicted_list):\n",
    "        metrics_df = compute_metrics(gt_mask, pred_mask)\n",
    "        metrics_list.append(metrics_df)\n",
    "    \n",
    "    # Concatenate individual DataFrames into one DataFrame\n",
    "    all_metrics_df = pd.concat(metrics_list, ignore_index=True)\n",
    "    \n",
    "    # Calculate the average of each column\n",
    "    avg_metrics_df = pd.DataFrame(all_metrics_df.mean()).T\n",
    "    avg_metrics_df.index = ['Average']  # Label the row as 'Average'\n",
    "    \n",
    "    return avg_metrics_df"
   ],
   "id": "8191af199fa200fa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Background subtraction",
   "id": "9fe9cfd0900d5764"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "rand_idx = random.randrange(len(query_d2_image_PIL_list))\n",
    "\n",
    "image = query_d2_image_PIL_list[rand_idx]\n",
    "gt_mask = query_d2_mask_PIL_list[rand_idx]\n",
    "\n",
    "left_mask, right_mask = get_painting_mask(image, method=METHOD)\n",
    "\n",
    "left_filled_mask, left_largest_components_mask, left_filled_largest_components_mask = fill_painting_mask(left_mask, side=\"left\")\n",
    "right_filled_mask, right_largest_components_mask, right_filled_largest_components_mask = fill_painting_mask(right_mask, side=\"right\")\n",
    "\n",
    "final_filled_mask = np.concatenate((left_filled_mask, right_filled_mask), axis=1)\n",
    "final_filled_largest_components_mask = np.concatenate((left_filled_largest_components_mask, right_filled_largest_components_mask), axis=1)\n",
    "\n",
    "if left_filled_mask[:, -1].any() and right_filled_mask[:, 0].any():\n",
    "    corrected_final_filled_mask = correct_vertical_transition_in_concatenated_mask(final_filled_mask)\n",
    "else:\n",
    "    corrected_final_filled_mask = final_filled_mask\n",
    "\n",
    "if left_filled_largest_components_mask[:, -1].any() and right_filled_largest_components_mask[:, 0].any():\n",
    "    corrected_final_filled_largest_components_mask = correct_vertical_transition_in_concatenated_mask(final_filled_largest_components_mask)\n",
    "else:\n",
    "    corrected_final_filled_largest_components_mask = final_filled_largest_components_mask\n",
    "\n",
    "show_images(\n",
    "    [image, left_mask, right_mask, \n",
    "     left_filled_mask, left_largest_components_mask, left_filled_largest_components_mask,\n",
    "     right_filled_mask, right_largest_components_mask, right_filled_largest_components_mask,\n",
    "     gt_mask, final_filled_mask, final_filled_largest_components_mask,\n",
    "     gt_mask, corrected_final_filled_mask, corrected_final_filled_largest_components_mask\n",
    "    ]\n",
    ")"
   ],
   "id": "6812d9d1573522ae",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "mask_output_folder = WEEK_3_RESULTS_PATH / \"Task_3\" / f\"mask_M_{METHOD}_MF_{APPLY_MEDIAN_FILTER}_KS_{KERNEL_SIZE}_NMR_{N_MARGIN_ROWS}_NMC_{N_MARGIN_COLS}\"\n",
    "mask_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "final_masks = defaultdict(list)\n",
    "for name, image, gt_mask in zip(sorted(QSD2_W3_PATH.glob(\"*.jpg\")), query_d2_image_PIL_list, query_d2_mask_PIL_list):\n",
    "    left_mask, right_mask = get_painting_mask(image, method=METHOD)\n",
    "    \n",
    "    left_filled_mask, left_largest_components_mask, left_filled_largest_components_mask = fill_painting_mask(left_mask, side=\"left\")\n",
    "    right_filled_mask, right_largest_components_mask, right_filled_largest_components_mask = fill_painting_mask(right_mask, side=\"right\")\n",
    "    \n",
    "    final_filled_mask = np.concatenate((left_filled_mask, right_filled_mask), axis=1)\n",
    "    final_filled_largest_components_mask = np.concatenate((left_filled_largest_components_mask, right_filled_largest_components_mask), axis=1)\n",
    "    \n",
    "    if left_filled_mask[:, -1].any() and right_filled_mask[:, 0].any():\n",
    "        corrected_final_filled_mask = correct_vertical_transition_in_concatenated_mask(final_filled_mask)\n",
    "    else:\n",
    "        corrected_final_filled_mask = final_filled_mask\n",
    "    \n",
    "    if left_filled_largest_components_mask[:, -1].any() and right_filled_largest_components_mask[:, 0].any():\n",
    "        corrected_final_filled_largest_components_mask = correct_vertical_transition_in_concatenated_mask(final_filled_largest_components_mask)\n",
    "    else:\n",
    "        corrected_final_filled_largest_components_mask = final_filled_largest_components_mask\n",
    "    \n",
    "    show_images(\n",
    "        [image, left_mask, right_mask, \n",
    "         left_filled_mask, left_largest_components_mask, left_filled_largest_components_mask,\n",
    "         right_filled_mask, right_largest_components_mask, right_filled_largest_components_mask,\n",
    "         gt_mask, final_filled_mask, final_filled_largest_components_mask,\n",
    "         gt_mask, corrected_final_filled_mask, corrected_final_filled_largest_components_mask\n",
    "        ],\n",
    "        output_file=str(mask_output_folder / f\"{name.stem}.png\")\n",
    "    )\n",
    "    \n",
    "    final_masks[\"final_filled_mask\"].append(final_filled_mask)\n",
    "    final_masks[\"final_filled_largest_components_mask\"].append(final_filled_largest_components_mask)\n",
    "    final_masks[\"corrected_final_filled_mask\"].append(corrected_final_filled_mask)\n",
    "    final_masks[\"corrected_final_filled_largest_components_mask\"].append(corrected_final_filled_largest_components_mask)"
   ],
   "id": "709fc1a1093e8362",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "all_avg_metrics_df = pd.DataFrame()\n",
    "for mask_name, query_background_mask_list in final_masks.items():\n",
    "    # Compute the average metrics for a list of masks and return a DataFrame\n",
    "    avg_metrics_df = compute_average_metrics(query_d2_mask_PIL_list, query_background_mask_list)\n",
    "    \n",
    "    # To export\n",
    "    avg_metrics_df[\"mask_name\"] = mask_name\n",
    "    all_avg_metrics_df = pd.concat([all_avg_metrics_df, avg_metrics_df])\n",
    "\n",
    "all_avg_metrics_df.to_csv(mask_output_folder / \"all_avg_metrics.csv\", index=False)"
   ],
   "id": "a8faf746e800e138",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Worst cases\n",
    "\n",
    "all_metrics_df = pd.DataFrame()\n",
    "for i, (gt_mask, pred_mask) in enumerate(zip(query_d2_mask_PIL_list, final_masks[\"corrected_final_filled_largest_components_mask\"])):\n",
    "    metrics_df = compute_metrics(gt_mask, pred_mask)\n",
    "    metrics_df[\"number\"] = i\n",
    "    all_metrics_df = pd.concat([all_metrics_df, metrics_df])\n",
    "    \n",
    "all_metrics_df.sort_values(by=\"F1-score\", ascending=True)"
   ],
   "id": "bf3a16358b7a523c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "all_avg_metrics_df",
   "id": "1835920eacf8cda0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Final implementation",
   "id": "84710429bcf01935"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T12:07:42.703981Z",
     "start_time": "2024-10-26T12:07:41.752445Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from src.background import get_painting_masks\n",
    "from src.denoising import denoise_image\n",
    "from src.metrics import compute_average_binary_mask_metrics\n",
    "from src.paths import QSD2_W3_PATH, WEEK_3_RESULTS_PATH\n",
    "from src.utils import show_images"
   ],
   "id": "de5ce6dca63723b3",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T12:07:42.723338Z",
     "start_time": "2024-10-26T12:07:42.704697Z"
    }
   },
   "cell_type": "code",
   "source": [
    "query_d2_image_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD2_W3_PATH.glob(\"*.jpg\"))]  # Load once\n",
    "query_d2_mask_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD2_W3_PATH.glob(\"*.png\"))]  # Load once"
   ],
   "id": "873d8433ca1027ef",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T12:07:43.311755Z",
     "start_time": "2024-10-26T12:07:42.835546Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Apply median filter\n",
    "query_d2_image_PIL_list = [denoise_image(image) for image in query_d2_image_PIL_list]"
   ],
   "id": "bf807d0a5410e42a",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T12:07:59.239096Z",
     "start_time": "2024-10-26T12:07:43.317843Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Parameters\n",
    "mask_output_folder = WEEK_3_RESULTS_PATH / \"Task_3\" / \"final_results\"\n",
    "mask_output_folder.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "painting_masks_list = []\n",
    "pbar = tqdm(zip(sorted(QSD2_W3_PATH.glob(\"*.jpg\")), query_d2_image_PIL_list, query_d2_mask_PIL_list))\n",
    "for name, image, gt_mask in pbar:\n",
    "    pbar.set_description(f\"Processing {name.stem}\")\n",
    "    painting_masks = get_painting_masks(image)\n",
    "    \n",
    "    show_images(\n",
    "        [image, gt_mask, painting_masks],\n",
    "        output_file=str(mask_output_folder / f\"{name.stem}.png\")\n",
    "    )\n",
    "    \n",
    "    painting_masks_list.append(painting_masks)"
   ],
   "id": "790b5e8351d4ca52",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing 00029: : 30it [00:15,  1.89it/s]\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-26T12:07:59.533734Z",
     "start_time": "2024-10-26T12:07:59.247069Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Compute the average metrics for a list of masks and return a DataFrame\n",
    "avg_metrics_df = compute_average_binary_mask_metrics(\n",
    "    ground_truth_list=query_d2_mask_PIL_list,\n",
    "    predicted_list=painting_masks_list\n",
    ")\n",
    "avg_metrics_df"
   ],
   "id": "ca5c586bd2597200",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "         Precision    Recall  F1-score      IoU\n",
       "Average   0.945635  0.992342  0.967817  0.93858"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1-score</th>\n",
       "      <th>IoU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.945635</td>\n",
       "      <td>0.992342</td>\n",
       "      <td>0.967817</td>\n",
       "      <td>0.93858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
