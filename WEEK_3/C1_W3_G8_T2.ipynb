{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from src.descriptors import LBPDescriptor, DCTDescriptor, WaveletDescriptor, GaborDescriptor\n",
    "\n",
    "from src.data import GT_QSD1_W3_LIST\n",
    "from src.paths import (\n",
    "    BBDD_PATH, \n",
    "    QSD1_W3_PATH,\n",
    "    WEEK_3_RESULTS_PATH\n",
    ")\n",
    "from src.similarities import HistogramIntersection, CosineSimilarity\n",
    "from src.metrics import MeanAveragePrecisionAtK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "database_image_PIL_list = [Image.open(db_img_path) for db_img_path in sorted(BBDD_PATH.glob(\"*.jpg\"))]  # Load once\n",
    "query_d1_image_PIL_list = [Image.open(query_img_path) for query_img_path in sorted(QSD1_W3_PATH.glob(\"*.jpg\"))]  # Load once"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "texture_descriptors = [\n",
    "    #WaveletDescriptor(wavelet='haar', level=3),  #triga molt poc\n",
    "    #WaveletDescriptor(wavelet='db1',  level=4),  #triga molt poc\n",
    "    #LBPDescriptor(num_points=8, radius=1),   # triga mig\n",
    "    # LBPDescriptor(num_points=24, radius=3),  # triga molt\n",
    "    GaborDescriptor(),\n",
    "    DCTDescriptor(N=10),                     # triga poc\n",
    "    DCTDescriptor(N=21),                     # triga poc\n",
    "    # DCTDescriptor(N=36),                   # triga poc\n",
    "    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "partition_levels = [5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make the execution faster we persist the partitions of the images for the next runs of the notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Partitioning at level 5: 100%|██████████| 30/30 [00:00<00:00, 137.16it/s]\n",
      "Saving images at level 5: 100%|██████████| 30/30 [00:01<00:00, 15.42it/s]\n",
      "Loading images at level 5: 100%|██████████| 287/287 [00:08<00:00, 34.79it/s]\n"
     ]
    }
   ],
   "source": [
    "def partition_image(image: Image.Image, N: int):\n",
    "    w, h = image.size\n",
    "    part_width, part_height = w // N, h // N\n",
    "    return [image.crop((col * part_width, row * part_height,\n",
    "                        (col + 1) * part_width, (row + 1) * part_height))\n",
    "            for row in range(N) for col in range(N)]\n",
    "\n",
    "\n",
    "def process_partitioned_images(path, PIL_list, partition_levels, mode='auto'):\n",
    "    # If mode is 'compute_notsave', skip loading/saving and just return computed partitions\n",
    "    if mode == 'compute_notsave':\n",
    "        partitioned_images = {level: [] for level in partition_levels}\n",
    "        for partition_level in partition_levels:\n",
    "            if partition_level == 1:\n",
    "                print(\"Partitioning at level 1\")\n",
    "                partitioned_images[partition_level] = [[img] for img in PIL_list]\n",
    "            else:\n",
    "                partitioned_images[partition_level] = [\n",
    "                    partition_image(img, partition_level) \n",
    "                    for img in tqdm(PIL_list, desc=f\"Partitioning at level {partition_level}\")\n",
    "                ]\n",
    "        return partitioned_images\n",
    "\n",
    "    partitioned_images = {}\n",
    "    \n",
    "    for partition_level in partition_levels:\n",
    "        partition_level_dir = path.with_name(f\"{path.stem}_level_{partition_level}{path.suffix}\")\n",
    "\n",
    "        # Load existing partitions from disk if they exist and mode allows loading\n",
    "        if mode != 'compute' and partition_level_dir.exists():\n",
    "            partitioned_images[partition_level] = []\n",
    "\n",
    "            for img_idx in tqdm(range(len(PIL_list)), desc=f\"Loading images at level {partition_level}\"): \n",
    "                partitions = []\n",
    "                block_idx = 0\n",
    "                while True:\n",
    "                    img_path = partition_level_dir / f\"img_{img_idx}_block_{block_idx}.jpg\"\n",
    "                    if not img_path.exists():\n",
    "                        break  \n",
    "                    with Image.open(img_path) as img:  # Use context manager\n",
    "                        partitions.append(img.copy())\n",
    "                    block_idx += 1\n",
    "\n",
    "                partitioned_images[partition_level].append(partitions)\n",
    "\n",
    "            continue  # Skip computation for this level\n",
    "\n",
    "        # If partitions don't exist, or if mode is 'compute', calculate and store partitions\n",
    "        partition_level_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        if partition_level == 1:\n",
    "            print(\"Partitioning at level 1\")\n",
    "            partitioned_images[partition_level] = [[img] for img in PIL_list]\n",
    "        else:\n",
    "            partitioned_images[partition_level] = [\n",
    "                partition_image(img, partition_level) \n",
    "                for img in tqdm(PIL_list, desc=f\"Partitioning at level {partition_level}\")\n",
    "            ]\n",
    "\n",
    "        # Save computed partitions to disk\n",
    "        for img_idx, partitions in tqdm(enumerate(partitioned_images[partition_level]), \n",
    "                                        total=len(partitioned_images[partition_level]), \n",
    "                                        desc=f\"Saving images at level {partition_level}\"):\n",
    "            for block_idx, block_img in enumerate(partitions):\n",
    "                block_img.save(partition_level_dir / f\"img_{img_idx}_block_{block_idx}.jpg\")\n",
    "\n",
    "    return partitioned_images\n",
    "\n",
    "partitioned_images_query = process_partitioned_images(WEEK_3_RESULTS_PATH/\"partitioned_query\",query_d1_image_PIL_list, partition_levels, mode='compute')\n",
    "partitioned_images_db = process_partitioned_images(WEEK_3_RESULTS_PATH/\"partitioned_db\",database_image_PIL_list, partition_levels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor:  Gabor_wavelengths_(3, 5, 7)_orientations_4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing partitions at level 5: 100%|██████████| 30/30 [00:05<00:00,  5.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor:  DCT_10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing partitions at level 5: 100%|██████████| 30/30 [00:13<00:00,  2.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Descriptor:  DCT_21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing partitions at level 5: 100%|██████████| 30/30 [00:13<00:00,  2.29it/s]\n"
     ]
    }
   ],
   "source": [
    "def process_partitioned_histograms(descriptors, partition_levels, partitioned_images):\n",
    "    partitioned_histograms = {}\n",
    "\n",
    "    for descriptor in descriptors:\n",
    "        print(\"Descriptor: \", descriptor.name)\n",
    "        partitioned_histograms[descriptor.name] = {}\n",
    "\n",
    "        for partition_level in partition_levels:\n",
    "            partitioned_histograms[descriptor.name][partition_level] = []\n",
    "\n",
    "            for partitions in tqdm(partitioned_images[partition_level], desc=f\"Processing partitions at level {partition_level}\"):\n",
    "                histograms_img = []\n",
    "                for partition_img in partitions:\n",
    "                    histogram_partition = descriptor.compute(np.array(partition_img))\n",
    "                    histograms_img.append(histogram_partition)\n",
    "\n",
    "                concatenated_histogram = np.concatenate(histograms_img, axis=0)\n",
    "                partitioned_histograms[descriptor.name][partition_level].append(concatenated_histogram)\n",
    "\n",
    "    return partitioned_histograms\n",
    "\n",
    "def save_load_histograms(path, compute_func, *args, load=True):\n",
    "    if path.exists() and load:\n",
    "        return load_histograms(path)\n",
    "    else:\n",
    "        histograms = compute_func(*args)\n",
    "        with open(path, 'wb') as f:\n",
    "            pickle.dump(histograms, f)\n",
    "        return histograms\n",
    "\n",
    "def load_histograms(filename):\n",
    "    with open(filename, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "\n",
    "partitioned_histograms_query = save_load_histograms(WEEK_3_RESULTS_PATH/\"partitioned_histograms_query.pkl\", process_partitioned_histograms, texture_descriptors, partition_levels, partitioned_images_query, load=True)\n",
    "partitioned_histograms_db = save_load_histograms(WEEK_3_RESULTS_PATH/\"partitioned_histograms_db.pkl\", process_partitioned_histograms, texture_descriptors, partition_levels, partitioned_images_db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_query_descriptor_distances(similarity_classes, texture_descriptors, partition_levels, partitioned_histograms_db, partitioned_histograms_query):\n",
    "    query_descriptor_distances_to_db_list = {}\n",
    "\n",
    "    for similarity in similarity_classes:\n",
    "        similarity_name = similarity.__class__.__name__\n",
    "        query_descriptor_distances_to_db_list[similarity_name] = {}\n",
    "\n",
    "        for descriptor in texture_descriptors:\n",
    "            descriptor_name = descriptor.name\n",
    "            print(f\"- {similarity_name} & {descriptor_name}\")\n",
    "            query_descriptor_distances_to_db_list[similarity_name][descriptor_name] = {}\n",
    "\n",
    "            for partition_level in partition_levels:\n",
    "                partitioned_db_desc = np.array(partitioned_histograms_db[descriptor_name][partition_level])\n",
    "                partitioned_query_desc = np.array(partitioned_histograms_query[descriptor_name][partition_level])\n",
    "\n",
    "                bb_similarity = similarity.compute(partitioned_query_desc, partitioned_db_desc)\n",
    "                query_descriptor_distances_to_db_list[similarity_name][descriptor_name][partition_level] = bb_similarity\n",
    "\n",
    "    return query_descriptor_distances_to_db_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_topk_distances(query_distances_to_bbdd: np.array, k: int = 1) -> tuple[list[list], list[list]]:\n",
    "    retrieved_bbdd_indices = np.argsort(query_distances_to_bbdd, axis=1)[:, :k]\n",
    "    \n",
    "    retrieved_bbdd_similarity = np.take_along_axis(query_distances_to_bbdd, retrieved_bbdd_indices, axis=1)\n",
    "    \n",
    "    return retrieved_bbdd_indices.tolist(), retrieved_bbdd_similarity.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity_classes = [\n",
    "    HistogramIntersection(),\n",
    "    CosineSimilarity()\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- HistogramIntersection & Gabor_wavelengths_(3, 5, 7)_orientations_4\n",
      "- HistogramIntersection & DCT_10\n",
      "- HistogramIntersection & DCT_21\n",
      "- CosineSimilarity & Gabor_wavelengths_(3, 5, 7)_orientations_4\n",
      "- CosineSimilarity & DCT_10\n",
      "- CosineSimilarity & DCT_21\n"
     ]
    }
   ],
   "source": [
    "query_descriptor_distances_to_db_list = compute_query_descriptor_distances(\n",
    "    similarity_classes          = similarity_classes,\n",
    "    texture_descriptors         = texture_descriptors,\n",
    "    partition_levels            = partition_levels,\n",
    "    partitioned_histograms_db   = partitioned_histograms_db,\n",
    "    partitioned_histograms_query= partitioned_histograms_query\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_top_k_db_entries(query_descriptor_distances_to_db_list, k, bprint=False):\n",
    "    retrieved_db = {}\n",
    "\n",
    "    for similarity_name, descriptors_dict in query_descriptor_distances_to_db_list.items():\n",
    "        retrieved_db[similarity_name] = {}\n",
    "        for descriptor_name, data_dict in descriptors_dict.items():\n",
    "            retrieved_db[similarity_name][descriptor_name] = {}\n",
    "\n",
    "            for partition_level, distances in data_dict.items():\n",
    "                topk_indices, topk_similarities = get_topk_distances(distances, k)\n",
    "                retrieved_db[similarity_name][descriptor_name][partition_level] = {\n",
    "                    \"indexes\": topk_indices,\n",
    "                    \"similarities\": topk_similarities\n",
    "                }\n",
    "                if bprint:\n",
    "                    print(f\"{similarity_name} - {descriptor_name} | BB Level {partition_level}:\")\n",
    "                    print(f\"Top-{k} Indices: {topk_indices}\\n\")\n",
    "\n",
    "    return retrieved_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistogramIntersection - Gabor_wavelengths_(3, 5, 7)_orientations_4 | BB Level 5:\n",
      "Top-5 Indices: [[7, 182, 217, 114, 4], [186, 189, 47, 177, 36], [128, 142, 104, 32, 76], [35, 40, 65, 120, 47], [262, 23, 138, 176, 235], [23, 176, 239, 278, 114], [21, 174, 105, 46, 200], [272, 120, 258, 202, 40], [13, 3, 11, 274, 78], [133, 93, 157, 142, 37], [286, 163, 147, 90, 150], [22, 202, 212, 40, 161], [91, 279, 101, 248, 102], [222, 245, 163, 47, 283], [219, 179, 155, 144, 35], [248, 102, 101, 168, 279], [94, 103, 46, 191, 239], [104, 161, 257, 132, 286], [74, 164, 106, 107, 40], [201, 48, 22, 243, 161], [252, 226, 248, 60, 261], [81, 163, 226, 60, 205], [280, 165, 114, 100, 182], [110, 93, 37, 131, 142], [258, 42, 212, 176, 150], [120, 40, 116, 24, 47], [106, 35, 30, 107, 148], [25, 35, 147, 90, 254], [93, 142, 110, 37, 157], [212, 202, 42, 258, 94]]\n",
      "\n",
      "HistogramIntersection - DCT_10 | BB Level 5:\n",
      "Top-5 Indices: [[7, 30, 1, 194, 53], [186, 1, 184, 194, 182], [238, 35, 47, 106, 128], [35, 194, 5, 30, 1], [262, 1, 92, 246, 165], [23, 1, 194, 184, 165], [21, 106, 35, 238, 272], [272, 35, 106, 182, 184], [13, 1, 30, 100, 151], [133, 1, 107, 165, 252], [286, 255, 258, 236, 161], [22, 1, 194, 165, 184], [91, 232, 101, 182, 93], [222, 272, 106, 35, 40], [219, 179, 1, 30, 194], [248, 30, 1, 93, 194], [184, 1, 142, 97, 194], [104, 1, 30, 92, 194], [164, 1, 30, 124, 194], [201, 1, 30, 194, 92], [252, 186, 101, 93, 30], [226, 77, 205, 251, 125], [280, 1, 108, 30, 165], [131, 30, 165, 1, 92], [258, 184, 1, 182, 90], [120, 106, 182, 35, 238], [30, 1, 165, 92, 194], [25, 1, 92, 30, 165], [93, 251, 30, 36, 1], [130, 184, 186, 1, 182]]\n",
      "\n",
      "HistogramIntersection - DCT_21 | BB Level 5:\n",
      "Top-5 Indices: [[7, 30, 1, 194, 53], [186, 1, 194, 184, 165], [128, 238, 106, 184, 35], [35, 194, 184, 1, 30], [262, 1, 92, 165, 16], [23, 1, 194, 184, 165], [21, 106, 258, 11, 35], [272, 184, 35, 106, 182], [1, 13, 100, 30, 92], [133, 1, 165, 92, 30], [286, 255, 236, 186, 161], [22, 1, 194, 184, 30], [91, 101, 232, 30, 251], [222, 272, 35, 184, 106], [219, 179, 1, 30, 266], [30, 1, 248, 194, 124], [1, 184, 194, 186, 165], [104, 1, 92, 30, 186], [164, 1, 30, 124, 165], [201, 1, 30, 92, 194], [252, 186, 1, 30, 101], [93, 251, 36, 30, 52], [1, 280, 30, 108, 165], [131, 30, 1, 165, 92], [258, 184, 1, 194, 30], [120, 182, 184, 272, 186], [30, 1, 165, 92, 194], [25, 1, 30, 92, 165], [93, 30, 1, 36, 251], [130, 184, 1, 186, 194]]\n",
      "\n",
      "CosineSimilarity - Gabor_wavelengths_(3, 5, 7)_orientations_4 | BB Level 5:\n",
      "Top-5 Indices: [[7, 182, 217, 119, 278], [186, 189, 177, 47, 36], [128, 104, 142, 32, 76], [35, 65, 40, 120, 236], [262, 23, 138, 176, 235], [23, 176, 114, 239, 135], [21, 174, 232, 105, 200], [272, 202, 24, 40, 120], [13, 3, 11, 61, 78], [133, 93, 157, 153, 244], [286, 163, 90, 147, 136], [22, 202, 212, 40, 161], [91, 279, 101, 248, 102], [222, 11, 161, 40, 47], [219, 179, 155, 129, 125], [248, 102, 101, 232, 174], [94, 191, 85, 192, 103], [104, 161, 193, 132, 255], [164, 74, 107, 106, 53], [201, 22, 48, 243, 106], [252, 226, 52, 60, 248], [81, 163, 226, 205, 60], [280, 165, 278, 114, 5], [131, 110, 93, 37, 142], [258, 42, 212, 24, 176], [120, 40, 24, 116, 47], [106, 107, 30, 148, 35], [25, 35, 106, 40, 90], [93, 142, 140, 110, 157], [202, 258, 94, 212, 22]]\n",
      "\n",
      "CosineSimilarity - DCT_10 | BB Level 5:\n",
      "Top-5 Indices: [[7, 27, 93, 30, 254], [186, 184, 194, 182, 142], [21, 35, 106, 251, 238], [35, 194, 30, 238, 254], [262, 246, 1, 16, 92], [23, 194, 1, 90, 184], [21, 106, 35, 272, 238], [272, 35, 106, 240, 238], [13, 151, 41, 20, 137], [133, 252, 107, 165, 1], [286, 63, 258, 255, 161], [22, 1, 194, 184, 142], [91, 232, 167, 182, 101], [222, 272, 35, 40, 106], [219, 179, 181, 263, 131], [248, 30, 1, 194, 165], [184, 142, 22, 186, 97], [104, 29, 1, 254, 92], [164, 254, 184, 30, 124], [201, 1, 266, 92, 194], [252, 101, 105, 238, 93], [285, 226, 205, 125, 206], [1, 92, 12, 108, 280], [131, 30, 165, 1, 266], [258, 184, 90, 186, 236], [120, 106, 35, 209, 238], [30, 1, 165, 194, 92], [25, 1, 92, 165, 16], [93, 251, 105, 128, 162], [130, 186, 29, 31, 278]]\n",
      "\n",
      "CosineSimilarity - DCT_21 | BB Level 5:\n",
      "Top-5 Indices: [[7, 30, 1, 194, 266], [186, 1, 194, 184, 165], [128, 238, 106, 35, 251], [35, 194, 5, 1, 184], [16, 1, 246, 92, 165], [23, 1, 194, 90, 184], [21, 162, 11, 206, 68], [272, 35, 106, 240, 184], [267, 13, 202, 100, 151], [133, 165, 107, 1, 252], [286, 132, 255, 161, 236], [22, 1, 194, 184, 165], [91, 232, 101, 236, 182], [222, 272, 35, 161, 106], [219, 179, 1, 266, 16], [248, 30, 194, 1, 124], [184, 5, 22, 194, 1], [104, 29, 51, 215, 186], [164, 30, 1, 254, 184], [201, 1, 266, 30, 92], [252, 101, 105, 93, 30], [93, 52, 128, 251, 36], [280, 1, 107, 92, 25], [131, 165, 1, 30, 194], [258, 184, 194, 182, 186], [120, 182, 272, 238, 240], [30, 1, 165, 194, 266], [25, 1, 92, 165, 30], [93, 36, 251, 30, 52], [130, 236, 182, 232, 186]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "retrieved_db = retrieve_top_k_db_entries(query_descriptor_distances_to_db_list, k, bprint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = [MeanAveragePrecisionAtK()]\n",
    "K = [1,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_results_dataframe(K, metrics, similarity_classes, texture_descriptors, partition_levels, retrieved_db, GT_QSD1_W3_LIST):\n",
    "    results = []\n",
    "\n",
    "    for k in K:\n",
    "        for metric in metrics:\n",
    "            for similarity in similarity_classes:\n",
    "                similarity_name = similarity.__class__.__name__\n",
    "                for descriptor in texture_descriptors:\n",
    "                    descriptor_name = descriptor.name\n",
    "\n",
    "                    for partition_level in partition_levels:\n",
    "                        indexes_retrieved = retrieved_db[similarity_name][descriptor_name][partition_level][\"indexes\"]\n",
    "                        map_val = round(metric.compute(GT_QSD1_W3_LIST, indexes_retrieved, k), 2)\n",
    "                        results.append({\n",
    "                            \"K\": k,\n",
    "                            \"Metric\": metric.__class__.__name__,\n",
    "                            \"Descriptor\": descriptor_name,\n",
    "                            \"Similarity\": similarity_name,\n",
    "                            \"Method\": f\"BB at level {partition_level}\",\n",
    "                            \"Result\": map_val,\n",
    "                            \"Indices\": indexes_retrieved,\n",
    "                        })\n",
    "\n",
    "    results_df = pd.DataFrame(results)\n",
    "    results_df_cleaned = results_df.drop(columns=[\"Indices\", \"Descriptor_id\", \"Similarity_id\"], errors='ignore')\n",
    "    return results_df_cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = compute_results_dataframe(K, metrics, similarity_classes, texture_descriptors, partition_levels, retrieved_db, GT_QSD1_W3_LIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>K</th>\n",
       "      <th>Metric</th>\n",
       "      <th>Descriptor</th>\n",
       "      <th>Similarity</th>\n",
       "      <th>Method</th>\n",
       "      <th>Result</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.93</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>HistogramIntersection</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>Gabor_wavelengths_(3, 5, 7)_orientations_4</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_10</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>5</td>\n",
       "      <td>MeanAveragePrecisionAtK</td>\n",
       "      <td>DCT_21</td>\n",
       "      <td>CosineSimilarity</td>\n",
       "      <td>BB at level 5</td>\n",
       "      <td>0.88</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    K                   Metric                                  Descriptor  \\\n",
       "0   1  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "1   1  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "2   1  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "3   1  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "4   1  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "5   1  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "6   5  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "7   5  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "8   5  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "9   5  MeanAveragePrecisionAtK  Gabor_wavelengths_(3, 5, 7)_orientations_4   \n",
       "10  5  MeanAveragePrecisionAtK                                      DCT_10   \n",
       "11  5  MeanAveragePrecisionAtK                                      DCT_21   \n",
       "\n",
       "               Similarity         Method  Result  \n",
       "0   HistogramIntersection  BB at level 5    0.87  \n",
       "1   HistogramIntersection  BB at level 5    0.90  \n",
       "2   HistogramIntersection  BB at level 5    0.83  \n",
       "3        CosineSimilarity  BB at level 5    0.93  \n",
       "4        CosineSimilarity  BB at level 5    0.87  \n",
       "5        CosineSimilarity  BB at level 5    0.87  \n",
       "6   HistogramIntersection  BB at level 5    0.90  \n",
       "7   HistogramIntersection  BB at level 5    0.91  \n",
       "8   HistogramIntersection  BB at level 5    0.88  \n",
       "9        CosineSimilarity  BB at level 5    0.94  \n",
       "10       CosineSimilarity  BB at level 5    0.87  \n",
       "11       CosineSimilarity  BB at level 5    0.88  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's put it all together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def task2(image_list, db_image_list , texture_descriptor, k= 5, similarity_class= CosineSimilarity(), partition_level=5):\n",
    "\n",
    "    # Flattened list of elements\n",
    "    image_list_flat = [img for sublist in image_list for img in sublist]\n",
    "\n",
    "    # List of positions\n",
    "    positions = [i for i, sublist in enumerate(image_list) for _ in sublist]\n",
    "\n",
    "    # PARTITION\n",
    "    partitioned_images_query = process_partitioned_images(WEEK_3_RESULTS_PATH/f\"partitioned_histograms_query2\",image_list_flat, [partition_level], mode=\"compute_notsave\")\n",
    "    partitioned_images_db = process_partitioned_images(WEEK_3_RESULTS_PATH/\"partitioned_db\",db_image_list, [partition_level])\n",
    "    \n",
    "    # COMPUTE HISTS\n",
    "    partitioned_histograms_query = save_load_histograms(WEEK_3_RESULTS_PATH/f\"partitioned_histograms_query2.pkl\", process_partitioned_histograms, [texture_descriptor], [partition_level], partitioned_images_query, load=False)\n",
    "    partitioned_histograms_db = save_load_histograms(WEEK_3_RESULTS_PATH/\"partitioned_histograms_db.pkl\", process_partitioned_histograms, [texture_descriptor], [partition_level], partitioned_images_db)\n",
    "\n",
    "    query_descriptor_distances_to_db_list = compute_query_descriptor_distances(\n",
    "        similarity_classes          = [similarity_class],\n",
    "        texture_descriptors         = [texture_descriptor],\n",
    "        partition_levels            = [partition_level],\n",
    "        partitioned_histograms_db   = partitioned_histograms_db,\n",
    "        partitioned_histograms_query= partitioned_histograms_query\n",
    "    )\n",
    "\n",
    "    retrieved_db = retrieve_top_k_db_entries(query_descriptor_distances_to_db_list, k)\n",
    "\n",
    "    list_all_paintings = list(list(list(list(retrieved_db.values())[0].values())[0].values())[0].values())[0]\n",
    "\n",
    "    list_all_images = [[] for _ in range(len(image_list))]\n",
    "\n",
    "    for i, l in enumerate(list_all_paintings):\n",
    "        index = positions[i]\n",
    "        list_all_images[index].append(l)\n",
    "\n",
    "    return list_all_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
